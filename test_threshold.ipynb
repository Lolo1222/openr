{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import Levenshtein\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "def ratio(s1, s2):\n",
    "    if not s1 and not s2:\n",
    "        return 1.0\n",
    "    distance = levenshtein_distance(s1, s2)\n",
    "    return (max(len(s1), len(s2)) - distance) / max(len(s1), len(s2))\n",
    "\n",
    "# 示例用法\n",
    "s1 = \"kitten\"\n",
    "s2 = \"sitting\"\n",
    "print(ratio(s1, ''))  # 输出相似度比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['答案1', None, '答案2', '答案3']\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicate_answers(querylist, answerlist):\n",
    "    seen_answers = set()\n",
    "    new_answers = []\n",
    "\n",
    "    for query, answer in zip(querylist, answerlist):\n",
    "        if answer not in seen_answers:\n",
    "            seen_answers.add(answer)\n",
    "            new_answers.append(answer)\n",
    "        else:\n",
    "            new_answers.append(None)  # 或者可以选择其他占位符，表示该答案被删除\n",
    "\n",
    "    return new_answers\n",
    "\n",
    "# 示例\n",
    "querylist = [\"问题1\", \"问题1\", \"问题2\", \"问题2\"]\n",
    "answerlist = [\"答案1\", \"答案1\", \"答案2\", \"答案3\"]\n",
    "querylist_len = [2,2]\n",
    "filtered_answers = remove_duplicate_answers(querylist, answerlist)\n",
    "print(filtered_answers)  # 输出: ['答案1', '答案2', None, '答案3', None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "new_querylist = []\n",
    "new_answerlist = []\n",
    "new_querylist_len = copy.deepcopy(querylist_len)\n",
    "\n",
    "# 记录每个查询对应的答案\n",
    "query_to_answers = {}\n",
    "for i in range(len(querylist)):\n",
    "    if querylist[i] not in query_to_answers:\n",
    "        query_to_answers[querylist[i]] = []\n",
    "    query_to_answers[querylist[i]].append(answerlist[i])\n",
    "\n",
    "# 处理每个查询及其对应的答案\n",
    "for i,query in enumerate(query_to_answers):\n",
    "    answers = query_to_answers[query]\n",
    "    unique_answers = []\n",
    "    seen_answers = set()\n",
    "    query_count = 0  # 记录当前查询的重复次数\n",
    "\n",
    "    for answer in answers:\n",
    "        if answer not in seen_answers:\n",
    "            # 检查当前答案与已添加的答案是否相似\n",
    "            if all(not ratio(answer, unique_answer) >0.9 for unique_answer in unique_answers):\n",
    "                unique_answers.append(answer)\n",
    "                seen_answers.add(answer)\n",
    "            else:\n",
    "                new_querylist_len[i] -= 1\n",
    "        else:\n",
    "            new_querylist_len[i] -= 1\n",
    "\n",
    "\n",
    "\n",
    "    # 更新新列表\n",
    "    for answer in unique_answers:\n",
    "        new_querylist.append(query)\n",
    "        new_answerlist.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities=[0.1,0.9,0.3,0.7]\n",
    "querylist = [\"问题1\", \"问题1\", \"问题2\", \"问题2\"]\n",
    "answerlist = [\"答案1\", \"答案1\", \"答案2\", \"答案3\"]\n",
    "querylist_len = [2,2]\n",
    "# 初始化新的列表\n",
    "new_querylist = []\n",
    "new_answerlist = []\n",
    "new_querylist_len = []\n",
    "new_probabilities = []  # 新的概率列表\n",
    "\n",
    "# 记录每个查询对应的答案及其概率\n",
    "query_to_answers = {}\n",
    "query_to_probs = {}\n",
    "for i in range(len(querylist)):\n",
    "    if querylist[i] not in query_to_answers:\n",
    "        query_to_answers[querylist[i]] = []\n",
    "        query_to_probs[querylist[i]] = []\n",
    "    query_to_answers[querylist[i]].append(answerlist[i])\n",
    "    query_to_probs[querylist[i]].append(probabilities[i])  # 假设 probabilities 是存储概率的列表\n",
    "\n",
    "# 处理每个查询及其对应的答案\n",
    "for query in query_to_answers:\n",
    "    answers = query_to_answers[query]\n",
    "    probs = query_to_probs[query]\n",
    "    unique_answers = []\n",
    "    unique_probs = []\n",
    "\n",
    "    for j in range(len(answers)):\n",
    "        answer = answers[j]\n",
    "        prob = probs[j]\n",
    "        # 检查当前答案与已添加的答案是否相似\n",
    "        found_similar = False\n",
    "        for k in range(len(unique_answers)):\n",
    "            if ratio(answer, unique_answers[k])>0.9:\n",
    "                unique_probs[k] += prob  # 合并概率\n",
    "                found_similar = True\n",
    "                break\n",
    "        \n",
    "        if not found_similar:\n",
    "            # 如果没有找到相似的答案，添加到唯一答案列表\n",
    "            unique_answers.append(answer)\n",
    "            unique_probs.append(prob)\n",
    "\n",
    "    # 更新新列表\n",
    "    for i in range(len(unique_answers)):\n",
    "        new_querylist.append(query)\n",
    "        new_answerlist.append(unique_answers[i])\n",
    "        new_querylist_len.append(answers.count(unique_answers[i]))  # 记录该答案的重复次数\n",
    "        new_probabilities.append(unique_probs[i])  # 添加合并后的概率\n",
    "\n",
    "# 更新原始列表\n",
    "querylist = new_querylist\n",
    "answerlist = new_answerlist\n",
    "querylist_len = new_querylist_len\n",
    "probabilities = new_probabilities  # 更新概率列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.7]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['问题1', '问题2', '问题2'] [2, 1, 1] ['答案1', '答案2', '答案3'] [1.0, 0.3, 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(new_querylist,new_querylist_len,new_answerlist,probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import ratio\n",
    "def is_sim(str1:str, str2:str) -> bool:\n",
    "    the_ratio = ratio(str1,str2)\n",
    "    return the_ratio > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(string_list:list):\n",
    "    result=[]\n",
    "    for string in string_list:\n",
    "        if not any(is_sim(string, unique) for unique in result):\n",
    "            result.append(string)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio(\"aaa\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa', 'bbb', 'ccc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list=[\"aaa\", \"bbb\", \"aaa\",\"ccc\"]\n",
    "merge(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/home/jiawei/.conda/envs/open_reasonser/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('/data2/OpenLLMs/math-similarity/Bert-MLM_arXiv-MP-class_zbMath')\n",
    "# model = SentenceTransformer('/data2/OpenLLMs/sentence-transformers/paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(sentences_pair):\n",
    "    embeddings = model.encode(sentences_pair)\n",
    "    embedding_1= model.encode(sentences_pair[0], convert_to_tensor=True)\n",
    "    embedding_2 = model.encode(sentences_pair[1], convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(embedding_1, embedding_2).cpu().numpy()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "\n",
    "# # 读取 train.jsonl 文件\n",
    "# with open('envs/MATH/dataset/train.jsonl', 'r', encoding='utf-8') as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# # 随机打乱行顺序\n",
    "# random.shuffle(lines)\n",
    "\n",
    "# # 选取前 500 行作为 for_gen.jsonl\n",
    "# for_gen_lines = lines[:500]\n",
    "\n",
    "# # 剩下的行作为 retain_train.jsonl\n",
    "# retain_train_lines = lines[500:]\n",
    "\n",
    "# # 将 for_gen_lines 写入 for_gen.jsonl 文件\n",
    "# with open('envs/MATH/dataset/for_gen.jsonl', 'w', encoding='utf-8') as f:\n",
    "#     f.writelines(for_gen_lines)\n",
    "\n",
    "# # 将 retain_train_lines 写入 retain_train.jsonl 文件\n",
    "# with open('envs/MATH/dataset/retain_train.jsonl', 'w', encoding='utf-8') as f:\n",
    "#     f.writelines(retain_train_lines)\n",
    "\n",
    "# print(\"文件分割完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_candidate_actions(log_content):\n",
    "    # 正则表达式匹配 Candidate action + 数字 的行\n",
    "    pattern = re.compile(r'Candidate action \\d: (.*)')\n",
    "    \n",
    "    # 用于存储提取的信息\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    \n",
    "    for line in log_content.splitlines():\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            # 如果匹配到 Candidate action 行，提取冒号后的信息\n",
    "            action_info = match.group(1)\n",
    "            current_group.append(action_info)\n",
    "        elif line.strip() == '********************************************************************************':\n",
    "            # 如果遇到分隔符，将当前组添加到 groups 中，并重置 current_group\n",
    "            if current_group:\n",
    "                groups.append(current_group)\n",
    "                current_group = []\n",
    "    \n",
    "    # 处理最后一个组\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    \n",
    "    return groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path=\"logs_terminal/vanila_mcts_math500.log\"\n",
    "log_content = read_log_file(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1:\n",
      "{'action': 'We can use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\left( \\\\frac{y}{x} \\\\right)$ to convert from rectangular coordinates to polar coordinates. ки\\n', 'prob': 0.25739426139958294, 'num_token': 53, 'finish_reason': 'stop'}\n",
      "{'action': 'To convert from rectangular coordinates to polar coordinates, we use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\left( \\\\frac{y}{x} \\\\right)$. ки\\n', 'prob': 0.24839519181502717, 'num_token': 52, 'finish_reason': 'stop'}\n",
      "{'action': 'To convert from rectangular coordinates to polar coordinates, we use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\left( \\\\frac{y}{x} \\\\right).$ ки\\n', 'prob': 0.24785813497191633, 'num_token': 53, 'finish_reason': 'stop'}\n",
      "{'action': 'To convert from rectangular coordinates to polar coordinates, we can use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\left( \\\\frac{y}{x} \\\\right).$ ки\\n', 'prob': 0.2463524118134735, 'num_token': 54, 'finish_reason': 'stop'}\n",
      "\n",
      "Group 2:\n",
      "{'action': 'We can use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\left( \\\\frac{y}{x} \\\\right)$ to convert from rectangular coordinates to polar coordinates. ки\\n', 'prob': 0.34536035371288365, 'num_token': 53, 'finish_reason': 'stop'}\n",
      "{'action': 'We can use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan\\\\left(\\\\frac{y}{x}\\\\right)$ to convert from rectangular coordinates to polar coordinates. ки\\n', 'prob': 0.336010585162825, 'num_token': 51, 'finish_reason': 'stop'}\n",
      "{'action': 'We can use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan \\\\frac{y}{x}$ to convert from rectangular coordinates to polar coordinates. ки\\n', 'prob': 0.31862906112429135, 'num_token': 47, 'finish_reason': 'stop'}\n",
      "\n",
      "Group 3:\n",
      "{'action': 'We can rewrite the double sum as ки\\n', 'prob': 0.3310552229017273, 'num_token': 10, 'finish_reason': 'stop'}\n",
      "{'action': 'Note that ки\\n', 'prob': 0.2515856895592855, 'num_token': 4, 'finish_reason': 'stop'}\n",
      "{'action': \"Let's use the Cauchy Product. ки\\n\", 'prob': 0.20568232058396294, 'num_token': 12, 'finish_reason': 'stop'}\n",
      "{'action': 'We can use the method of infinite series to simplify the given expression. ки\\n', 'prob': 0.21167676695502433, 'num_token': 17, 'finish_reason': 'stop'}\n",
      "\n",
      "Group 4:\n",
      "{'action': 'We can rewrite the double sum as ки\\n', 'prob': 0.34788801365259003, 'num_token': 10, 'finish_reason': 'stop'}\n",
      "{'action': 'We can use the Cauchy Product to rewrite the double sum as ки\\n', 'prob': 0.3079268488245638, 'num_token': 17, 'finish_reason': 'stop'}\n",
      "{'action': 'Let $S = \\\\sum_{j = 1}^\\\\infty \\\\sum_{k = 1}^\\\\infty \\\\frac{1}{(j + k)^3}.$ ки\\n', 'prob': 0.3441851375228462, 'num_token': 36, 'finish_reason': 'stop'}\n",
      "\n",
      "Group 5:\n",
      "{'action': 'To find $f(-2)$, we substitute $x=-2$ into the expression for $f(x)$:\\n$f(-2) = \\\\frac{3(-2)-2}{(-2)-2} = \\\\frac{-6}{-4} = \\\\frac{3}{2}$. ки\\n', 'prob': 0.2921591203819276, 'num_token': 64, 'finish_reason': 'stop'}\n",
      "{'action': 'We can evaluate each term separately: ки\\n', 'prob': 0.16173474216866338, 'num_token': 9, 'finish_reason': 'stop'}\n",
      "{'action': 'Step 1: To find $f(-2)$, we substitute $x=-2$ into the expression for $f(x)$:\\n$$f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2.$$ ки\\n', 'prob': 0.28873294215365586, 'num_token': 76, 'finish_reason': 'stop'}\n",
      "{'action': 'We can evaluate $f(-2)$ by plugging in $x=-2$ into the equation:\\n\\\\[f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2.\\\\] ки\\n', 'prob': 0.2573731952957532, 'num_token': 69, 'finish_reason': 'stop'}\n",
      "\n",
      "Group 6:\n",
      "{'action': 'We can substitute $x=-2$, $x=-1$, and $x=0$ into the expression for $f(x)$ to find $f(-2)$, $f(-1)$, and $f(0)$, respectively. ки\\n', 'prob': 0.25562747993979024, 'num_token': 50, 'finish_reason': 'stop'}\n",
      "{'action': 'To find $f(-2)$, we substitute $x=-2$ into the expression for $f(x)$:\\n$f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2$. ки\\n', 'prob': 0.26236015836817994, 'num_token': 71, 'finish_reason': 'stop'}\n",
      "{'action': 'We can substitute $-2$, $-1$, and $0$ into the expression for $f(x)$ to find the values of $f(-2)$, $f(-1)$, and $f(0)$ respectively. ки\\n', 'prob': 0.235330631834518, 'num_token': 47, 'finish_reason': 'stop'}\n",
      "{'action': 'First, we find $f(-2)$ by plugging $-2$ into the function:\\n$f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2$. ки\\n', 'prob': 0.2466817298575118, 'num_token': 66, 'finish_reason': 'stop'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 提取信息\n",
    "groups = extract_candidate_actions(log_content)\n",
    "\n",
    "# 打印结果\n",
    "for i, group in enumerate(groups):\n",
    "    if i > 5:\n",
    "        break\n",
    "    print(f\"Group {i+1}:\")\n",
    "    for action in group:\n",
    "        print(action)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'组号': 1, '平均相似度': 0.9928252, '最大相似度': 0.9998011, '最小相似度': 0.9898933, '相似度标准差': 0.0034404902}\n",
      "{'组号': 2, '平均相似度': 0.98817253, '最大相似度': 1.0000001, '最小相似度': 0.9822587, '相似度标准差': 0.008363396}\n",
      "{'组号': 3, '平均相似度': 0.5680475, '最大相似度': 0.7986666, '最小相似度': 0.22002785, '相似度标准差': 0.21750563}\n",
      "{'组号': 4, '平均相似度': 0.9083789, '最大相似度': 0.98200315, '最小相似度': 0.8614379, '相似度标准差': 0.052713}\n",
      "{'组号': 5, '平均相似度': 0.79483134, '最大相似度': 0.9774318, '最小相似度': 0.6057078, '相似度标准差': 0.17773308}\n",
      "{'组号': 6, '平均相似度': 0.9336293, '最大相似度': 0.9869937, '最小相似度': 0.8859408, '相似度标准差': 0.035924952}\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import ratio\n",
    "\n",
    "def calculate_levenshtein_ratios(group):\n",
    "    \"\"\"计算组内所有action之间的Levenshtein比率\"\"\"\n",
    "    import ast\n",
    "    ratios = []\n",
    "    \n",
    "    # 将字符串形式的字典转换为实际的字典对象\n",
    "    actions = []\n",
    "    for item in group:\n",
    "        try:\n",
    "            action_dict = ast.literal_eval(item)\n",
    "            actions.append(action_dict['action'])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # 计算每对action之间的比率\n",
    "    for i in range(len(actions)):\n",
    "        for j in range(i+1, len(actions)):\n",
    "            # r = ratio(actions[i], actions[j])\n",
    "            r = compute_similarity([actions[i], actions[j]])\n",
    "            ratios.append(r)\n",
    "            \n",
    "    return ratios\n",
    "\n",
    "# 为每个组计算比率\n",
    "group_ratios_list = []\n",
    "for i, group in enumerate(groups):\n",
    "    if i > 5:\n",
    "        break\n",
    "    group_ratios = calculate_levenshtein_ratios(group)\n",
    "    group_ratios_list.append(group_ratios)\n",
    "    \n",
    "# 计算每个组的统计信息并存储在变量中\n",
    "import numpy as np\n",
    "group_statistics = []\n",
    "\n",
    "for idx, group_ratios in enumerate(group_ratios_list):\n",
    "    if idx > 5:\n",
    "        break\n",
    "    group_stat = {}\n",
    "    group_stat[\"组号\"] = idx + 1\n",
    "    if group_ratios:\n",
    "        group_stat[\"平均相似度\"] = np.mean(group_ratios)\n",
    "        group_stat[\"最大相似度\"] = np.max(group_ratios)\n",
    "        group_stat[\"最小相似度\"] = np.min(group_ratios)\n",
    "        group_stat[\"相似度标准差\"] = np.std(group_ratios)\n",
    "    else:\n",
    "        group_stat[\"无法计算相似度\"] = \"组内action不足\"\n",
    "    group_statistics.append(group_stat)\n",
    "\n",
    "# 打印统计信息\n",
    "for stat in group_statistics:\n",
    "    print(stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99027205, 0.9898933, 0.99032855, 0.9998011, 0.9938306, 0.9928255]\n",
      "[1.0000001, 0.9822587, 0.9822587]\n",
      "[0.31996503, 0.71736205, 0.7986666, 0.71037513, 0.22002785, 0.6418884]\n",
      "[0.98200315, 0.8816957, 0.8614379]\n",
      "[0.6057078, 0.9774318, 0.9728621, 0.6335184, 0.6127383, 0.9667295]\n",
      "[0.9186898, 0.9709877, 0.9370198, 0.8859408, 0.9869937, 0.9021439]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(group_ratios_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import ratio\n",
    "\n",
    "def calculate_levenshtein_similarity_matrix(sentences):\n",
    "    \"\"\"计算句子列表中每对句子的Levenshtein相似度，并返回相似度矩阵\"\"\"\n",
    "    num_sentences = len(sentences)\n",
    "    similarity_matrix = np.zeros((num_sentences, num_sentences))\n",
    "    \n",
    "    for i in range(num_sentences):\n",
    "        for j in range(num_sentences):\n",
    "            similarity_matrix[i, j] = ratio(sentences[i], sentences[j])\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer('/data2/OpenLLMs/sentence-transformers/paraphrase-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('/data2/OpenLLMs/math-similarity/Bert-MLM_arXiv-MP-class_zbMath')\n",
    "\n",
    "sentences = [\n",
    "    \"To find $f(-2)$, we substitute $x=-2$ into the expression for $f(x)$:\\n$f(-2) = \\\\frac{3(-2)-2}{(-2)-2} = \\\\frac{-6}{-4} = \\\\frac{3}{2}$. ки\\n\",\n",
    "    \"We can evaluate each term separately: ки\\n\",\n",
    "    \"Step 1: To find $f(-2)$, we substitute $x=-2$ into the expression for $f(x)$:\\n$$f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2.$$ ки\\n\",\n",
    "    \"We can evaluate $f(-2)$ by plugging in $x=-2$ into the equation:\\n\\\\[f(-2) = \\\\frac{3(-2)-2}{-2-2} = \\\\frac{-6-2}{-4} = \\\\frac{-8}{-4} = 2.\\\\] ки\\n\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "# [4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9786, 0.9421, 0.9869, 0.8330, 0.8740, 0.8348],\n",
      "        [0.9786, 1.0000, 0.9238, 0.9744, 0.8174, 0.8741, 0.8190],\n",
      "        [0.9421, 0.9238, 1.0000, 0.9474, 0.7952, 0.8448, 0.8022],\n",
      "        [0.9869, 0.9744, 0.9474, 1.0000, 0.8732, 0.9046, 0.8736],\n",
      "        [0.8330, 0.8174, 0.7952, 0.8732, 1.0000, 0.9625, 0.9947],\n",
      "        [0.8740, 0.8741, 0.8448, 0.9046, 0.9625, 1.0000, 0.9637],\n",
      "        [0.8348, 0.8190, 0.8022, 0.8736, 0.9947, 0.9637, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\n",
    "    \"We want to find the least positive integer multiple of 30 that can be written with only the digits 0 and 2. ки\\n\",\n",
    "    \"The least positive integer multiple of 30 that can be written with only the digits 0 and 2 is $\\\\boxed{20}$. The answer is: 20 кики\\n\",\n",
    "    \"We can start by listing out the multiples of 30: 30, 60, 90, 120, 150, 180, ... ки\\n\",\n",
    "    \"To find the least positive integer multiple of 30 that can be written with only the digits 0 and 2, we need to find the smallest positive integer $n$ such that $10^{n-1} + 2$ is divisible by 30. ки\\n\",\n",
    "    \"To find the least positive integer multiple of 30, we need to find the smallest number that is divisible by both 2 and 3. ки\\n\",\n",
    "    \"Since we are looking for a multiple of 30, we need to find a number that is divisible by both 2 and 3. ки\\n\",\n",
    "    \"To find the least positive integer multiple of 30, we need to find the least positive integer that is divisible by both 3 and 10. ки\\n\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities=[0.1,0.9,0.3,0.7]\n",
    "querylist = [\"问题1\", \"问题1\", \"问题2\", \"问题2\"]\n",
    "answerlist = [\"答案1\", \"答案1\", \"答案2\", \"答案3\"]\n",
    "querylist_len = [2,2]\n",
    "# 初始化新的列表\n",
    "new_querylist = []\n",
    "new_answerlist = []\n",
    "new_querylist_len = []\n",
    "new_probabilities = []  # 新的概率列表\n",
    "\n",
    "# 记录每个查询对应的答案及其概率\n",
    "query_to_answers = {}\n",
    "query_to_probs = {}\n",
    "for i in range(len(querylist)):\n",
    "    if querylist[i] not in query_to_answers:\n",
    "        query_to_answers[querylist[i]] = []\n",
    "        query_to_probs[querylist[i]] = []\n",
    "    query_to_answers[querylist[i]].append(answerlist[i])\n",
    "    query_to_probs[querylist[i]].append(probabilities[i])  # 假设 probabilities 是存储概率的列表\n",
    "\n",
    "# 处理每个查询及其对应的答案\n",
    "for query in query_to_answers:\n",
    "    answers = query_to_answers[query]\n",
    "    probs = query_to_probs[query]\n",
    "    unique_answers = []\n",
    "    unique_probs = []\n",
    "    answer_counts = {}  # 用于记录每个答案的出现次数\n",
    "\n",
    "    for j in range(len(answers)):\n",
    "        answer = answers[j]\n",
    "        prob = probs[j]\n",
    "        # 检查当前答案与已添加的答案是否相似\n",
    "        found_similar = False\n",
    "        for k in range(len(unique_answers)):\n",
    "            if ratio(answer, unique_answers[k])>0.9:\n",
    "                unique_probs[k] += prob  # 合并概率\n",
    "                answer_counts[unique_answers[k]] += 1  # 更新出现次数\n",
    "                found_similar = True\n",
    "                break\n",
    "        \n",
    "        if not found_similar:\n",
    "            # 如果没有找到相似的答案，添加到唯一答案列表\n",
    "            unique_answers.append(answer)\n",
    "            unique_probs.append(prob)\n",
    "            answer_counts[answer] = 1  # 初始化出现次数\n",
    "\n",
    "    # 更新新列表\n",
    "    for i in range(len(unique_answers)):\n",
    "        new_querylist.append(query)\n",
    "        new_answerlist.append(unique_answers[i])\n",
    "        new_querylist_len.append(answer_counts[unique_answers[i]])  # 记录该答案的重复次数\n",
    "        new_probabilities.append(unique_probs[i])  # 添加合并后的概率\n",
    "\n",
    "# 更新原始列表\n",
    "querylist = new_querylist\n",
    "answerlist = new_answerlist\n",
    "querylist_len = new_querylist_len\n",
    "probabilities = new_probabilities  # 更新概率列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_querylist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 更新新列表\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(unique_answers)):\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mnew_querylist\u001b[49m\u001b[38;5;241m.\u001b[39mappend(query)\n\u001b[1;32m     45\u001b[0m     new_answerlist\u001b[38;5;241m.\u001b[39mappend(unique_answers[i])\n\u001b[1;32m     46\u001b[0m     new_querylist_len\u001b[38;5;241m.\u001b[39mappend(answer_counts[unique_answers[i]])  \u001b[38;5;66;03m# 记录该答案的重复次数\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_querylist' is not defined"
     ]
    }
   ],
   "source": [
    "probabilities=[0.1,0.9,0.3,0.7]\n",
    "querylist = [\"问题1\", \"问题1\", \"问题2\", \"问题2\"]\n",
    "answerlist = [\"答案1\", \"答案1\", \"答案2\", \"答案3\"]\n",
    "# ... existing code ...\n",
    "# 记录每个查询对应的答案及其概率\n",
    "query_to_answers = {}\n",
    "query_to_probs = {}\n",
    "for i in range(len(querylist)):\n",
    "    if querylist[i] not in query_to_answers:\n",
    "        query_to_answers[querylist[i]] = []\n",
    "        query_to_probs[querylist[i]] = []\n",
    "    query_to_answers[querylist[i]].append(answerlist[i])\n",
    "    query_to_probs[querylist[i]].append(probabilities[i])  # 假设 probabilities 是存储概率的列表\n",
    "\n",
    "for query in query_to_answers:\n",
    "    answers = query_to_answers[query]\n",
    "    probs = query_to_probs[query]\n",
    "    unique_answers = []\n",
    "    unique_probs = []\n",
    "    answer_counts = {}  # 用于记录每个答案的出现次数\n",
    "\n",
    "    for j in range(len(answers)):\n",
    "        answer = answers[j]\n",
    "        prob = probs[j]\n",
    "        # 检查当前答案与已添加的答案是否相似\n",
    "        found_similar = False\n",
    "        for k in range(len(unique_answers)):\n",
    "            if ratio(answer, unique_answers[k]) > 0.9:\n",
    "                unique_probs[k] += prob  # 合并概率\n",
    "                answer_counts[unique_answers[k]] += 1  # 更新出现次数\n",
    "                answerlist[j] = '<deleted>'  # 标记为已合并的答案\n",
    "                probs[j] = float('-inf')  # 设置概率为负无穷\n",
    "                found_similar = True\n",
    "                break\n",
    "        \n",
    "        if not found_similar:\n",
    "            # 如果没有找到相似的答案，添加到唯一答案列表\n",
    "            unique_answers.append(answer)\n",
    "            unique_probs.append(prob)\n",
    "            answer_counts[answer] = 1  # 初始化出现次数\n",
    "\n",
    "    # 更新新列表\n",
    "    for i in range(len(unique_answers)):\n",
    "        new_querylist.append(query)\n",
    "        new_answerlist.append(unique_answers[i])\n",
    "        new_querylist_len.append(answer_counts[unique_answers[i]])  # 记录该答案的重复次数\n",
    "        new_probabilities.append(unique_probs[i])  # 添加合并后的概率\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['问题1', '问题2', '问题2'] [2, 1, 1] ['答案1', '答案2', '答案3'] [1.0, 0.3, 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(new_querylist,new_querylist_len,new_answerlist,probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def calculate_querylist_len(querylist):\n",
    "    # 统计每个查询出现的次数\n",
    "    query_counts = Counter(querylist)\n",
    "    \n",
    "    # 获取所有独特的查询，并保持顺序\n",
    "    unique_queries = []\n",
    "    for query in querylist:\n",
    "        if query not in unique_queries:\n",
    "            unique_queries.append(query)\n",
    "    \n",
    "    # 生成querylist_len，表示每个独特查询在querylist中出现的次数\n",
    "    querylist_len = [query_counts[query] for query in unique_queries]\n",
    "    \n",
    "    return querylist_len\n",
    "\n",
    "# 示例\n",
    "querylist = ['问题1', '问题2', '问题2', '问题2', '问题3']\n",
    "querylist_len = calculate_querylist_len(querylist)\n",
    "print(querylist_len)  # 输出: [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.23595506 0.91034483 0.70758123]\n",
      " [0.23595506 1.         0.22680412 0.30939227]\n",
      " [0.91034483 0.22680412 1.         0.7440273 ]\n",
      " [0.70758123 0.30939227 0.7440273  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = calculate_levenshtein_similarity_matrix(sentences)\n",
    "print(similarity_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_reasonser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
